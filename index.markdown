---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
---


<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>Jamie Morgenstern's Homepage</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="style-drop.css">
	<link rel="stylesheet" href="mystyle.css">
</head>
<body>
  <label for="show-menu" class="show-menu">Show Menu</label>
  <input type="checkbox" id="show-menu" role="button">
  <ul id="menu">
    <li><a href="#">Home</a></li>
    <li>
      <a href="#">Teaching &#65516;</a>
      <ul class="hidden">
	<li><a href="https://courses.cs.washington.edu/courses/cse599j/22wi/"> Foundations :) of Fairness in Machine Learning  (Winter 2022)</a></li>
	
	<li><a href="https://courses.cs.washington.edu/courses/cse547/21au/"> Introduction to Machine Learning  (Fall 2021)</a></li>
	
	<li><a href="https://courses.cs.washington.edu/courses/cse312/21wi/"> Foundations of Computing  (Spring 2021)</a></li>

		<li><a href="https://courses.cs.washington.edu/courses/cse547/20au/"> Introduction to Machine Learning  (Fall 2020)</a></li>
	
	<li><a href="https://courses.cs.washington.edu/courses/cse547/20sp/"> Introduction to Machine Learning  (Spring 2020)</a></li>
	<li><a href="https://courses.cs.washington.edu/courses/cse599m/20wi/"> Foundations of Fairness in Machine Learning  (Winter 2020)</a></li>
        			  <li><a href="teaching/f18-fairml/index.html"> Foundations of Fairness in Machine Learning  (Fall 2018)</a></li>
			  <li><a href="teaching/s18-6550/index.html"> Design and Analysis of Algorithms (Spring 2018)</a></li>
			  	<li><a href="teaching/su-122/index.html"> Principles of Imperative Computation (Su 2012)</a></li>
<!--				<li><a href="#">What We Do</a></li>-->
			</ul>
		</li>
		<li><a href="#pubs">Publications</a></li>
		<li>
			<a href="workshops.html">Workshops/Tutorials &#65516;</a>
			<ul class="hidden">
			  <li><a href="workshops.html#agtds-ec">AGT + Data Science, EC 2016</a></li>
			  <li><a href="workshops.html#dagstuhl">Dagstuhl 2017</a></li>
			</ul>
		</li>
		<li><a href="#service">Service</a></li>
<!--		<li><a href="#">Contact</a></li>-->
	</ul>




<div style="height:80px"></div>	
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-23385241-2', 'auto');
  ga('send', 'pageview');

</script>

<div id="top">
<div class="myphoto">&nbsp;</div>


<div class="hello"><strong> Jamie Morgenstern</strong><br>
  <!--</font>
<font face="helvetica, ariel, 'sans serif'">--><br>
 Assistant Professor in the <a href="https://www.cs.washington.edu"> Paul G. Allen School of Computer Science & Engineering</a><br> at the
  <a href="http://www.washington.edu">University of Washington</a><br>
Office: <br>
<p> Email: 'jamiemmt'   'at' 'cs 'dot' 'washington' 'dot' 'edu' </p>
<p>
<hr >
<p>
<!--<font face="palatino, helvetica, ariel, 'sans serif'">-->

<div class="main-text">
I am an assistant professor in the Paul G. Allen School of Computer Science &
Engineering at the University of Washington.  I was previously an assistant
professor in the School of Computer Science at Georgia Tech. Prior to starting
as faculty, I was fortunate to be hosted
by <a href="http://cis.upenn.edu/~mkearns">Michael
Kearns</a>, <a href="http://cis.upenn.edu/~aaroth">Aaron Roth</a>,
and <a href="https://sites.google.com/site/quaerereverum9/"> Rakesh Vohra </a>
as a Warren Center fellow at the University of Pennsylvania. I completed my PhD
working with <a href="http://ttic.uchicago.edu/~avrim/"> Avrim Blum </a> at
Carnegie Mellon University.

I study the social impact of machine learning and
the impact of social behavior on ML's guarantees. How should machine learning be
made robust to behavior of the people generating training or test data for it?
How should ensure that the models we design do not exacerbate inequalities
already present in society?

  <!-- <a href="cv.pdf"
onClick="ga('send', 'event', { eventCategory: 'Download', eventAction:
'cv', eventLabel: 'cv'});">here</a>.-->



<h2> Working papers </h2>


<!-- i

<script type="text/javascript">
<!--
var arxiv_authorid = "0000-0003-3753-8405";
</script>
<style type="text/css">
div.arxivfeed {margin-bottom: 5px; width:140px;}
</style>
<script type="text/javascript" src="https://arxiv.org/js/myarticles.js"></script> 

<div id="arxivfeed"></div>
-->


<a href="http://arxiv.org/abs/2202.05797"> Distributionally Robust Data Join.</a>
Pranjal Awasthi, Christopher Jung, Jamie Morgenstern.<br>

<a href="https://arxiv.org/abs/2206.11183"> Active Learning with Safety Constraints. </a> 
Romain Camilleri, Andrew Wagenmaker, Jamie Morgenstern, Lalit Jain, Kevin Jamieson.
<br>

<a href="https://arxiv.org/abs/2206.02667">Multi-learner risk reduction under endogenous participation dynamics.</a>
Sarah Dean, Mihaela Curmei, Lillian J. Ratliff, Jamie Morgenstern, Maryam Fazel
<br>


<a href="https://arxiv.org/abs/2202.05881">Optimal Spend Rate Estimation and Pacing for Ad Campaigns with Budgets.</a>
Bhuvesh Kumar, Jamie Morgenstern, Okke Schrijvers.
<br>

<a href="https://www.ajlunited.org/federal-office-call"> Facial Recognition Technologies in the Wild: A Call for a Federal Office</a>, Erik Learned-Miller, Vicente Ordóñez, Jamie Morgenstern, and Joy Buolamwini.<br> 

<a href="https://som.yale.edu/sites/default/files/CompetitionDigitalPlatformsStigler19.pdf?fbclid=IwAR00e4ef5Cg1nx27m3rU7UHdNMeOu-DyIiisEVSxCZYwbqlg1gPHz4Pb2PE">Committee
for the Study of Digital Platforms, Market Structure and Antitrust
Subcommittee Report</a>, joint with Fiona Scott Morton (chair),
Theodore Nierenberg, Pascal Bouvier, Ariel Ezrachi, Bruno Jullien,
Roberta Katz, Gene Kimmelman, and A. Douglas Melamed. <br>

<br>

  <a href="https://arxiv.org/abs/1902.11097"> Predictive Inequity  in  Object Detection
, joint with Benjamin Wilson and Judy Hoffman. Code can  be found <a href="https://github.com/benjaminrwilson/inequity-release"> here.</a> News coverage in
</a> <a href="https://vox.com/future-perfect/2019/3/5/18251924/self-driving-car-racial-bias-study-autonomous-vehicle-dark-skin">
Vox</a>, <a href="https://www.businessinsider.com/self-driving-cars-worse-at-detecting-dark-skin-study-says-2019-3">
Businesss
Insider</a>, <a href="https://www.theguardian.com/technology/shortcuts/2019/mar/13/driverless-cars-racist">
The
Guardian</a>, <a href="https://www.nbcnews.com/mach/video/people-of-color-could-be-at-risk-if-self-driving-cars-aren-t-properly-trained-study-says-1494218819954">

 NBC News<a>.<br>

      <br>


<a href="https://arxiv.org/abs/1803.09010"> Datasheets for
Datasets </a>, a project I've been working on with Timnit Gebru,
Briana Vecchione, Jennifer Wortman Vaughn, Hanna Wallach, Hal Daume
III, and Kate Crawford. We're proposing transparency and
standardization of the documentation accompanying datasets.

	<h2 id="Mentoring">Mentoring </h2>
	I'm  very fortunate  to be advising the following excellent students:<br>

	<a href="http://bhuveshkumar.com/">Bhuvesh Kumar</a> (PhD, SCS, joint with Jake Abernethy)<br>
	Yuanyuan (Chloe) Yang (PhD) <br>
        
	Jie (Claire) Zhang  (PhD) <br>

	Daniel Jiang   (PhD) <br>
	
	Benjamin Wilson (MS)<br>
        Angel (Alex) Cabrera, (BS) <br>
        Varun Gupta,(BS) <br>
        Dhamma Kimpara, (BS) <br>
	And excellent postdocs:<br>
	Matthäus Kleindessner <br>
	Sarah Dean <br>
<h2 id="service">Service </h2>

In 2020, I was an area chair for ICML, on the SPC for EC, ICLR, and COLT.
I served as general cochair
for <a href="fatconference.org">FAT* 2019</a>, which took place
in Atlanta!
In 2019, I served as an SPC  member for EC and ICML. 
For 2018, I was on the PC for EC, ICML, FAT*, WWW, and ALT. In 2017, I
was on the PC for EC, ICML, NetEcon, and FAT/ML. I also served on the
EC PC in 2016.

<h2>Funding</h2>

My research is currently supported by:

An NSF Career award, "Strategic and Equity Considerations in Machine Learning".
 The <a href="https://ml.utexas.edu/ifml">Institute for Foundations of Machine Learning</a>, an NSF-funded AI Center joint
between UT Austin, UW, Witchitaw State, and Microsoft Research.
<a href="https://toc4fairness.org/"> The Theory of Computing for Fairness</a>, A Simons collaboration project.

Previously, I was  fortunate to be supported by the Simons
Award for Graduate Students in Theoretical Computer Science
(2014-2016), an NSF GFRP fellowship, as well as the Microsoft Research
Graduate Women's Scholarship.
   


<h2 id="pubs">Publications </h2>
<link rel="stylesheet" href="table-color.css">
  <table class="t2" >

    <tbody>


      <tr> <th>ICML 2022 </th><td> <a href="https://arxiv.org/abs/2006.04960">Individual Preference Stability for Clustering</a></td><td>Saba Ahmadi, Pranjal Awasthi, Samir Khuller, Matthäus Kleindessner, Jamie Morgenstern, Pattara Sukprasert, Ali Vakilian</td><td></td></tr>


   <tr> <th>ICML 2022 </th><td> <a href="https://arxiv.org/abs/2006.06879">Active Sampling for Min-Max Fairness.</a></td><td>  
Jacob Abernethy, 
Pranjal Awasthi, Matthäus Kleindessner,Jamie Morgenstern,
Chris Russel, Claire Zhang.</td><td></td></tr>

      <tr>     <th>EC 2022 </th><td> <a href="https://arxiv.org/abs/2205.13026">Preference Dynamics Under Personalized Recommendations.</a></td><td> Sarah Dean and Jamie Morgenstern.</td><td></td></tr>
      <tr>
        <th>FaccT 2021</th><td>  <a href="https://arxiv.org/abs/2102.08410"> Evaluating Fairness of Machine Learning Models Under Uncertain and Incomplete Information. </a></td><td> Pranjal Awasthi, Alex Beutel,  Matthäus Kleindessner, Jamie Morgenstern, and Xuezhi Wang.</td><td></td></tr>

           
      <Tr>
        <th>AISTATS 2020</th><td> <a href="https://arxiv.org/pdf/1906.03284.pdf">Equalized odds postprocessing under imperfect group information. </a> </td><td> Pranjal Awasthi,  Matthäus Kleindessner, Jamie Morgenstern.</td><td></td></tr>

         <tr>
           <th>WINE 2020</th><td> <a href="https://arxiv.org/abs/2009.13741">Competition Alleviates Present Bias in Task Completion.</a> </td><td> Aditya Saraf, Anna Karlin, and Jamie Morgenstern.</td><td></td></tr>
	 
       <tr>   <th>AIES (AI, Ethics and Society) 2020</th><td>  <a href="https://arxiv.org/abs/2002.03256">Diversity and Inclusion in Subset Selection.</a> </td><td> Alex Hanna, Dylan Baker, Emily Denton, Nyalleng Moorosi, Ben Hutchinson, Timnit Gebru, Meg Mitchell, Jamie Morgenstern. </td><td></td></tr>
        

      <tr><th>NeurIPS 2019</th><td> <a href="https://papers.nips.cc/paper/9334-learning-auctions-with-robust-incentive-guarantees">Learning Auctions with Incentive Guarantees. </a> </td><td> Jacob Abernethy, Rachel Cummings, Bhuvesh Kumar, Jamie Morgenstern, Samuel Taggart.</td><td></td></tr>


<tr><th>NeurIPS 2019</th><td> <a href="https://arxiv.org/abs/1902.11281">Multi-Criteria Dimensionality Reduction with Applications to Fairness
  </a> </td><td> 
    Jamie Morgenstern, Samira Samadi, Mohit Singh, Uthaipon Tantipongpipat, Santosh Vempala.</td><td></td></tr>


<tr><th>VIS 2019</th><td> <a href="https://arxiv.org/abs/1904.05419">FairVis:
      Visual Analytics for Discovering Intersectional Bias in Machine
      Learning. </a> </td><td> Ángel Alexander Cabrera, Will Epperson, Fred
    Hohman, Minsuk Kahng, Jamie Morgenstern, Duen Horng
    Chau.</td><td></td></tr>


<tr><th>ICML 2019</th><td> <a href="https://arxiv.org/abs/1901.08668">Guarantees for Spectral Clustering with Fairness Constraints. </a> </td><td> Matthäus Kleindessner, Samira Samadi, Pranjal Awasthi, Jamie Morgenstern.</td><td></td></tr>



<tr><th>ICML 2019</th><td> <a href="https://arxiv.org/abs/1901.08628"> Fair k-center clustering for data summarization. </a> </td><td> Matthäus Kleindessner, Pranjal Awasthi, Jamie Morgenstern.</td><td></td></tr>



<tr><th>NeurIPS 2018</th><td> <a href="http://arxiv.org/abs/1811.00103">The Price of Fair PCA: One Extra Dimension. </a> </td><td> Samira Samadi, Uthaipon Tantipongpipat, Mohit Singh, Jamie Morgenstern, and Santosh Vempala.</td><td></td></tr>
</tr>
      
      <tr><th>NeurIPS 2018</th><td> <a href="https://arxiv.org/abs/1801.03423">A Smoothed Analysis of the Greedy Algorithm.</a> </td><td> Sampath Kannan, Jamie Morgenstern, Aaron Roth, Bo Waggoner, and Steven Wu.</td><td></td></tr>

      <tr><th>ICML 2017</th><td> <a href="https://arxiv.org/abs/1611.03071">Fairness in Reinforcement Learning.</a> </td><td>  Shahin Jabbari, Matthew Joseph, Michael Kearns, Jamie Morgenstern, and Aaron Roth.</td><td></td></tr>

  <tr><th>EC 2017</th><td>Fairness Incentives for Myopic Agents. </td><td>  Sampath Kannan, Michael Kearns, Jamie Morgenstern, Mallesh Pai, Aaron Roth, Rakesh Vohra, and Zhiwei Steven Wu.</td><td><a href="http://arxiv.org/abs/1705.02321">arxiv</a></td></tr>
  
    <tr><th>WINE 2016</th><td> Strategic Network Formation with Attack and Immunization </td><td>  Sanjeev Goyal, Shahin Jabbari, Michael Kearns, Sanjeev Khanna, Jamie Morgenstern.</td><td><a href="https://arxiv.org/abs/1511.05196">arxiv</a></td></tr>

    <tr><th>NeurIPS 2016</th><td> Fairness in Learning: Classic and Contextual Bandits. </td><td>  Matthew Joseph, Michael Kearns, Jamie Morgenstern, and Aaron Roth.</td><td><a href="http://arxiv.org/abs/1605.07139">arxiv</a></td></tr>
    
  <tr><th>EC 2016</th><td><a href="papers/simple-complements.pdf">Simple Mechanisms for Agents with Complements</a> </td><td> Michal Feldman, Ophir Friedler, Jamie Morgenstern, Guy Reiner</td><td><a href="http://arxiv.org/abs/1603.07939">arxiv</a></td></tr>
  
  <tr><th>COLT 2016</th><td><a href="papers/multi-nips.pdf">Learning Simple Auctions</a> </td><td> Jamie Morgenstern, Tim Roughgarden</td><td><a href="http://arxiv.org/abs/1604.03171">arxiv</a></td></tr>

  
  <tr><th>STOC 2016</th><td><a href="papers/pricing-long.pdf">Do Prices Coordinate Markets?</a> <a href="papers/pricing-short.pdf">(short version)</a></td><td>Justin Hsu, Jamie Morgenstern, Ryan Rogers, Aaron Roth, Rakesh Vohra</td><td><a href="http://arxiv.org/abs/1511.00925">arxiv</a></td></tr>


<tr><th>NeurIPS 2015</th>
 <td><a href="papers/auction-pseudo.pdf" style="display:block;">The Pseudo-Dimension of Nearly Optimal Auctions </a><p style="color:red;">Selected for a spotlight presentation,<!-- along with 16.7% of accepted papers and --> along with 3.6% of submissions.</p></td>
  <td>Jamie Morgenstern and Tim Roughgarden</td><td><a href="http://arxiv.org/abs/1506.03684">arxiv</a></td></tr>

<tr><th>EC 2015</th><td><a href="papers/private-ttc.pdf">Private Pareto-Optimal Exchange</a></td><td>Sampath Kannan, Jamie Morgenstern, Ryan Rogers, and Aaron Roth</td><td><a href="http://arxiv.org/abs/1407.2641">arxiv</a></td></tr>

<tr><th>EC 2015</th><td><a href="papers/simple-strategies.pdf">Simple Auctions with Simple Strategies</a></td><td>Nikhil Devanur, Jamie Morgenstern, Vasilis Syrgkanis, S. Matthew Weinberg</td><td></td></tr>


<tr><th>EC 2015</th><td><a href="papers/opaque-transactions.pdf">Learning What's Going On: Reconstruction Preferences and Priorities from Opaque Transactions</a></td><td>Avrim Blum, Yishay Mansour, Jamie Morgenstern</td><td><a href="http://arxiv.org/abs/1408.6575">arxiv</a></td></tr>


<tr><th>IJCAI 2015</th><td><a href="papers/impartial-review.pdf">Impartial Peer Review</a></td><td>David Kurokawa, Omer Lev, Jamie Morgenstern, Ariel Procaccia</td><td></td></tr>

<tr><th>SODA 2015</th><td><a href="papers/school-truth.pdf">Approximately Stable, School Optimal, and Student-Truthful Many-to-One Matchings (via Differential Privacy)</a></td><td>Sampath Kannan, Jamie Morgenstern, Aaron Roth, Steven Wu</td><td><a href="http://arxiv.org/abs/1407.2640">arxiv</a></td></tr>


<tr><th>AAAI 2015</th><td>Learning Valuation Distributions from Partial Observation</td><td>Avrim Blum, Yishay Mansour, Jamie Morgenstern</td><td><a href="http://arxiv.org/abs/1407.2855">arxiv</a></td></tr>

<tr><th>ITCS 2015</th><td><a href="papers/privacy-seq.pdf">Privacy-preserving Public Information in Sequential Games</a></td><td>Avrim Blum, Jamie Morgenstern, Ankit Sharma, Adam Smith</td><td><a href="http://arxiv.org/abs/1402.4488">arxiv</a></td></tr>


<tr><th>AAAI 2013</th><td><a href="papers/aaai-13.pdf">How Bad is Selfish Voting?</a></td><td>Simina Br&acirc;nzei, Ioannis Caragiannis, Jamie Morgenstern, Ariel D. Procaccia</td><td></td></tr>


<tr><th> COSN 2013</th><td> Hierarchical community decomposition via oblivious routing techniques </td><td>William Sean Kennedy, Jamie Morgenstern, Gordon Wilfong, Lisa Zhang</td><td></td></tr>


<tr><th>APPROX 2012</th><td><a href="papers/approx-12.pdf">Additive Approximation for Near-Perfect Phylogeny Construction</a></td><td>Pranjal Awasthi, Avrim Blum, Jamie Morgenstern, Or Sheffet</td><td></td></tr>


<tr><th>AAAI 2012</th><td><a href="papers/aaai-12.pdf">On Maxsum Fair Cake Divisions</a></td><td>Steven J. Brams, Michal Feldman, John K. Lai, Jamie Morgenstern, Ariel D. Procaccia</td><td></td></tr>



<tr><th>STM 2011</th><td><a href="papers/stm11-lpfcs-preproc.pdf">A proof-carrying File system with Revocable and Use-once Certificates</a> (Conference on Security and Trust Management)</td><td>Jamie Morgenstern, Deepak Garg, Frank Pfenning</td><td></td></tr>


<tr><th>ICFP 2010</th><td><a href="papers/ml10sectyp.pdf">Security-typed Programming Within Dependently Typed Programming</a></td><td>Jamie Morgenstern, Dan Licata</td><td></td></tr>

    </tbody>
  </table>
  
<h2> Workshops </h2>

      
      
      <tr><th>DebugML 2019, colocated with ICLR.</th><td> Discovery of Intersectional Bias in Machine Learning Using Automatic Subgroup Generation.
	</td><td>Angel Cabrera, Minsuk Kahng, Fred Hohman, Jamie Morgenstern and Duen Horng Chau.</td><td></td></tr><br>
      <br>
      
      <tr><th>FairUMAP 2019.</th><td> On the Compatibility of Privacy and Fairness. </td><td> Rachel Cummings, Varun Gupta, Dhamma Kimpara, Jamie Morgenstern.</td><td></td></tr><br>

   <h2> Thesis </h2>

      <p><b><a href="thesis-draft.pdf">Ph.D</a>, Market Algorithms: Incentives, Learning, and Privacy (Defended May 2015)</b><br> <a href="thesis-old.pdf">Original CMU Tech Report</a> (Not updated for typos)<br/> <p> 


</div>


</body>
</html>
